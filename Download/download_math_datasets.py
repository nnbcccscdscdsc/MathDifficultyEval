#!/usr/bin/env python3
"""
æ•°å­¦æ•°æ®é›†ä¸‹è½½è„šæœ¬
ä¸‹è½½Hendrycks MATHå’ŒMATH-500æ•°æ®é›†åˆ°æœ¬åœ°
"""

import os
import sys
from datasets import load_dataset
import pandas as pd
from datetime import datetime
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def download_hendrycks_math():
    """
    ä¸‹è½½Hendrycks MATHæ•°æ®é›†
    æ¥æº: https://huggingface.co/datasets/EleutherAI/hendrycks_math
    """
    logger.info("ğŸš€ å¼€å§‹ä¸‹è½½Hendrycks MATHæ•°æ®é›†...")
    
    try:
        # è·å–æ‰€æœ‰å¯ç”¨çš„å­é›†
        configs = ['algebra', 'counting_and_probability', 'geometry', 'intermediate_algebra', 'number_theory', 'prealgebra', 'precalculus']
        logger.info(f"ğŸ“‹ å‘ç° {len(configs)} ä¸ªå­é›†: {', '.join(configs)}")
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        save_dir = "data/hendrycks_math"
        os.makedirs(save_dir, exist_ok=True)
        
        all_train_data = []
        all_test_data = []
        
        # ä¸‹è½½æ¯ä¸ªå­é›†
        for config in configs:
            try:
                logger.info(f"ğŸ“¥ ä¸‹è½½å­é›†: {config}")
                dataset = load_dataset("EleutherAI/hendrycks_math", config)
                
                # åˆå¹¶è®­ç»ƒé›†
                if 'train' in dataset:
                    train_df = dataset['train'].to_pandas()
                    train_df['subset'] = config
                    all_train_data.append(train_df)
                    logger.info(f"   - è®­ç»ƒé›†: {len(train_df)} ä¸ªæ ·æœ¬")
                
                # åˆå¹¶æµ‹è¯•é›†
                if 'test' in dataset:
                    test_df = dataset['test'].to_pandas()
                    test_df['subset'] = config
                    all_test_data.append(test_df)
                    logger.info(f"   - æµ‹è¯•é›†: {len(test_df)} ä¸ªæ ·æœ¬")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ ä¸‹è½½å­é›† {config} å¤±è´¥: {e}")
                continue
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        if all_train_data:
            combined_train = pd.concat(all_train_data, ignore_index=True)
            train_path = f"{save_dir}/train.csv"
            combined_train.to_csv(train_path, index=False, encoding='utf-8')
            logger.info(f"ğŸ’¾ åˆå¹¶è®­ç»ƒé›†å·²ä¿å­˜: {train_path} ({len(combined_train)} ä¸ªæ ·æœ¬)")
        
        if all_test_data:
            combined_test = pd.concat(all_test_data, ignore_index=True)
            test_path = f"{save_dir}/test.csv"
            combined_test.to_csv(test_path, index=False, encoding='utf-8')
            logger.info(f"ğŸ’¾ åˆå¹¶æµ‹è¯•é›†å·²ä¿å­˜: {test_path} ({len(combined_test)} ä¸ªæ ·æœ¬)")
        
        # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
        info = {
            "dataset_name": "Hendrycks MATH",
            "source": "https://huggingface.co/datasets/EleutherAI/hendrycks_math",
            "download_time": datetime.now().isoformat(),
            "configs": configs,
            "train_samples": len(combined_train) if all_train_data else 0,
            "test_samples": len(combined_test) if all_test_data else 0,
            "total_samples": (len(combined_train) if all_train_data else 0) + (len(combined_test) if all_test_data else 0),
            "columns": list(combined_train.columns) if all_train_data else [],
            "subset_distribution": combined_train['subset'].value_counts().to_dict() if all_train_data else {},
            "level_distribution": combined_train['level'].value_counts().to_dict() if all_train_data else {},
            "type_distribution": combined_train['type'].value_counts().to_dict() if all_train_data else {}
        }
        
        import json
        info_path = f"{save_dir}/dataset_info.json"
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(info, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ“‹ æ•°æ®é›†ä¿¡æ¯å·²ä¿å­˜: {info_path}")
        
        return True
        logger.info(f"âœ… æˆåŠŸåŠ è½½Hendrycks MATHæ•°æ®é›†")
        logger.info(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        logger.info(f"   - è®­ç»ƒé›†: {len(dataset['train'])} ä¸ªæ ·æœ¬")
        logger.info(f"   - æµ‹è¯•é›†: {len(dataset['test'])} ä¸ªæ ·æœ¬")
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        save_dir = "data/hendrycks_math"
        os.makedirs(save_dir, exist_ok=True)
        
        # ä¿å­˜è®­ç»ƒé›†
        train_df = dataset['train'].to_pandas()
        train_path = f"{save_dir}/train.csv"
        train_df.to_csv(train_path, index=False, encoding='utf-8')
        logger.info(f"ğŸ’¾ è®­ç»ƒé›†å·²ä¿å­˜: {train_path}")
        
        # ä¿å­˜æµ‹è¯•é›†
        test_df = dataset['test'].to_pandas()
        test_path = f"{save_dir}/test.csv"
        test_df.to_csv(test_path, index=False, encoding='utf-8')
        logger.info(f"ğŸ’¾ æµ‹è¯•é›†å·²ä¿å­˜: {test_path}")
        
        # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
        info = {
            "dataset_name": "Hendrycks MATH",
            "source": "https://huggingface.co/datasets/EleutherAI/hendrycks_math",
            "download_time": datetime.now().isoformat(),
            "train_samples": len(train_df),
            "test_samples": len(test_df),
            "total_samples": len(train_df) + len(test_df),
            "columns": list(train_df.columns),
            "level_distribution": train_df['level'].value_counts().to_dict(),
            "type_distribution": train_df['type'].value_counts().to_dict()
        }
        
        import json
        info_path = f"{save_dir}/dataset_info.json"
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(info, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ“‹ æ•°æ®é›†ä¿¡æ¯å·²ä¿å­˜: {info_path}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ä¸‹è½½Hendrycks MATHæ•°æ®é›†å¤±è´¥: {e}")
        return False

def download_math_500():
    """
    ä¸‹è½½MATH-500æ•°æ®é›†
    æ¥æº: https://huggingface.co/datasets/HuggingFaceH4/MATH-500
    """
    logger.info("ğŸš€ å¼€å§‹ä¸‹è½½MATH-500æ•°æ®é›†...")
    
    try:
        # åŠ è½½æ•°æ®é›†
        dataset = load_dataset("HuggingFaceH4/MATH-500")
        logger.info(f"âœ… æˆåŠŸåŠ è½½MATH-500æ•°æ®é›†")
        logger.info(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        logger.info(f"   - æµ‹è¯•é›†: {len(dataset['test'])} ä¸ªæ ·æœ¬")
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        save_dir = "data/math_500"
        os.makedirs(save_dir, exist_ok=True)
        
        # ä¿å­˜æµ‹è¯•é›†
        test_df = dataset['test'].to_pandas()
        test_path = f"{save_dir}/test.csv"
        test_df.to_csv(test_path, index=False, encoding='utf-8')
        logger.info(f"ğŸ’¾ æµ‹è¯•é›†å·²ä¿å­˜: {test_path}")
        
        # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
        info = {
            "dataset_name": "MATH-500",
            "source": "https://huggingface.co/datasets/HuggingFaceH4/MATH-500",
            "download_time": datetime.now().isoformat(),
            "test_samples": len(test_df),
            "total_samples": len(test_df),
            "columns": list(test_df.columns) if len(test_df) > 0 else []
        }
        
        import json
        info_path = f"{save_dir}/dataset_info.json"
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(info, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ“‹ æ•°æ®é›†ä¿¡æ¯å·²ä¿å­˜: {info_path}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ä¸‹è½½MATH-500æ•°æ®é›†å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¯ å¼€å§‹ä¸‹è½½æ•°å­¦æ•°æ®é›†")
    logger.info("=" * 50)
    
    # æ£€æŸ¥ç½‘ç»œè¿æ¥
    try:
        import requests
        response = requests.get("https://huggingface.co", timeout=10)
        logger.info("âœ… ç½‘ç»œè¿æ¥æ­£å¸¸")
    except Exception as e:
        logger.error(f"âŒ ç½‘ç»œè¿æ¥å¤±è´¥: {e}")
        logger.info("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ä»£ç†è®¾ç½®")
        return
    
    # ä¸‹è½½Hendrycks MATHæ•°æ®é›†
    success1 = download_hendrycks_math()
    
    logger.info("-" * 30)
    
    # ä¸‹è½½MATH-500æ•°æ®é›†
    success2 = download_math_500()
    
    logger.info("=" * 50)
    logger.info("ğŸ“‹ ä¸‹è½½æ€»ç»“:")
    logger.info(f"   Hendrycks MATH: {'âœ… æˆåŠŸ' if success1 else 'âŒ å¤±è´¥'}")
    logger.info(f"   MATH-500: {'âœ… æˆåŠŸ' if success2 else 'âŒ å¤±è´¥'}")
    
    if success1 and success2:
        logger.info("ğŸ‰ æ‰€æœ‰æ•°æ®é›†ä¸‹è½½å®Œæˆï¼")
    else:
        logger.info("âš ï¸ éƒ¨åˆ†æ•°æ®é›†ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 