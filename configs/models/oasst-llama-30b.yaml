# OASST RLHF LLaMA 30B 模型配置
model:
  name: "Yhyu13/oasst-rlhf-2-llama-30b-7k-steps-hf"
  display_name: "OASST RLHF LLaMA 30B"
  description: "30B参数的RLHF优化模型，数学推理和对话能力强"
  
# GPU配置
gpu:
  num_gpus: 4                    # 使用4个GPU
  max_memory_per_gpu: "16GB"     # 每个GPU最大内存
  device_map: "auto"             # 自动设备映射
  max_memory:                    # 多GPU内存分配
    "0": "16GB"
    "1": "16GB"
    "2": "16GB"
    "3": "16GB"
  
# 量化配置
quantization:
  default: "4bit"                # 默认使用4bit量化
  options:
    4bit:
      load_in_4bit: true
      bnb_4bit_compute_dtype: "float16"
      bnb_4bit_quant_type: "nf4"
      bnb_4bit_use_double_quant: true
    8bit:
      load_in_8bit: true
    none:
      load_in_4bit: false
      load_in_8bit: false

# 生成参数
generation:
  max_new_tokens: 1024           # 支持很长输出
  do_sample: true
  temperature: 0.5
  top_p: 0.9
  top_k: 60
  repetition_penalty: 1.1
  pad_token_id: null  # 自动设置
  eos_token_id: null  # 自动设置
  return_full_text: false

# 模型特定设置
model_specific:
  trust_remote_code: true
  torch_dtype: "float16"
  low_cpu_mem_usage: true
  max_length: 8192               # 支持8K上下文
  
# 评估设置
evaluation:
  max_samples_per_run: 50        # 每次评估最大样本数（减少内存压力）
  timeout_seconds: 10800         # 评估超时时间（3小时）
  batch_size: 1                  # 批处理大小
  
# 提示模板
prompt_template: |
  You are a highly skilled mathematician and AI assistant trained on extensive mathematical data.
  Please provide a detailed, step-by-step solution to the following mathematical problem:

  Problem: {problem}

  I will solve this problem step by step: 