#!/usr/bin/env python3
"""
æ¢ç´¢DeepMathæ•°æ®é›†

è¿™ä¸ªè„šæœ¬çš„ä¸»è¦åŠŸèƒ½ï¼š
1. åŠ è½½å’Œæ¢ç´¢DeepMath-103Kæ•°æ®é›†
2. åˆ†ææ•°æ®é›†çš„éš¾åº¦åˆ†å¸ƒï¼ˆä»-1.0åˆ°10.0ï¼‰
3. åˆ›å»ºåŒ…å«æ‰€æœ‰éš¾åº¦ç­‰çº§çš„è¯„ä¼°æ•°æ®é›†
4. ä¿å­˜æ•°æ®é›†ä¿¡æ¯å’Œæ ·æœ¬ç¤ºä¾‹

DeepMathæ•°æ®é›†ç‰¹ç‚¹ï¼š
- åŒ…å«103,022ä¸ªæ•°å­¦é—®é¢˜
- éš¾åº¦ç­‰çº§ä»-1.0åˆ°10.0
- æ¶µç›–ä»£æ•°ã€å¾®ç§¯åˆ†ã€å‡ ä½•ã€æ•°è®ºç­‰å¤šä¸ªæ•°å­¦é¢†åŸŸ
- æ¯ä¸ªé—®é¢˜éƒ½æœ‰è¯¦ç»†çš„è§£ç­”æ­¥éª¤
"""

import os
import json
import argparse
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
import pandas as pd
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))
from scripts.utils import ConfigLoader, setup_logging

class DeepMathDatasetExplorer:
    """DeepMathæ•°æ®é›†æ¢ç´¢å™¨
    
    è¿™ä¸ªç±»è´Ÿè´£ï¼š
    1. åŠ è½½DeepMathæ•°æ®é›†
    2. åˆ†ææ•°æ®é›†ç»“æ„å’Œéš¾åº¦åˆ†å¸ƒ
    3. åˆ›å»ºè¯„ä¼°ç”¨çš„å­æ•°æ®é›†
    4. ä¿å­˜æ•°æ®é›†ä¿¡æ¯
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æ¢ç´¢å™¨"""
        # è®¾ç½®æ—¥å¿—è®°å½•
        setup_logging()
        self.logger = logging.getLogger(__name__)
        
        # DeepMathæ•°æ®é›†çš„åŸºæœ¬ä¿¡æ¯
        self.deepmath_info = {
            'name': 'zwhe99/DeepMath-103K',  # Hugging Faceä¸Šçš„æ•°æ®é›†åç§°
            'description': 'DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and Verifiable Mathematical Dataset',
            'paper': 'arXiv:2504.11456',  # ç›¸å…³è®ºæ–‡
            'difficulty_levels': ['Level 5', 'Level 6', 'Level 7', 'Level 8', 'Level 9'],  # å®˜æ–¹éš¾åº¦ç­‰çº§
            'topics': [
                'Algebra', 'Calculus', 'Number Theory', 'Geometry', 
                'Probability', 'Discrete Mathematics'
            ],  # ä¸»è¦æ•°å­¦ä¸»é¢˜
            'expected_features': ['question', 'final_answer', 'difficulty', 'topic', 'r1_solutions']  # æœŸæœ›çš„ç‰¹å¾åˆ—
        }
    
    def try_load_deepmath(self):
        """å°è¯•åŠ è½½DeepMathæ•°æ®é›†
        
        è¿™ä¸ªæ–¹æ³•ä¼šï¼š
        1. é¦–å…ˆå°è¯•ä½¿ç”¨å®˜æ–¹è·¯å¾„åŠ è½½æ•°æ®é›†
        2. å¦‚æœå¤±è´¥ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
        3. è¿”å›åŠ è½½æˆåŠŸçš„æ•°æ®é›†æˆ–None
        
        Returns:
            dataset: åŠ è½½æˆåŠŸçš„æ•°æ®é›†å¯¹è±¡ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        print(f"\n{'='*60}")
        print(f"ğŸ” å°è¯•åŠ è½½DeepMathæ•°æ®é›†")
        print(f"{'='*60}")
        
        try:
            # å¯¼å…¥Hugging Faceçš„datasetsåº“
            from datasets import load_dataset
            
            # é¦–å…ˆå°è¯•å®˜æ–¹è·¯å¾„
            print(f"å°è¯•åŠ è½½: {self.deepmath_info['name']}")
            dataset = load_dataset(self.deepmath_info['name'], split='train')
            
            print(f"âœ… DeepMathæ•°æ®é›†åŠ è½½æˆåŠŸ!")
            print(f"ğŸ“Š æ ·æœ¬æ•°: {len(dataset)}")
            print(f"ğŸ“‹ ç‰¹å¾: {list(dataset.features.keys())}")
            
            return dataset
            
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            print(f"ğŸ’¡ å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„...")
            
            # å¦‚æœå®˜æ–¹è·¯å¾„å¤±è´¥ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
            # æœ‰æ—¶å€™æ•°æ®é›†åç§°å¯èƒ½æœ‰ä¸åŒçš„å˜ä½“
            alternative_paths = [
                'zwhe99/deepmath-103k',  # å°å†™ç‰ˆæœ¬
                'zwhe99/DeepMath',       # ç®€åŒ–ç‰ˆæœ¬
                'deepmath-103k'          # æœ€ç®€åŒ–ç‰ˆæœ¬
            ]
            
            for path in alternative_paths:
                try:
                    print(f"å°è¯•åŠ è½½: {path}")
                    dataset = load_dataset(path, split='train')
                    print(f"âœ… æˆåŠŸåŠ è½½: {path}")
                    print(f"ğŸ“Š æ ·æœ¬æ•°: {len(dataset)}")
                    print(f"ğŸ“‹ ç‰¹å¾: {list(dataset.features.keys())}")
                    return dataset
                except Exception as e2:
                    print(f"âŒ å¤±è´¥: {path} - {e2}")
                    continue
            
            # æ‰€æœ‰è·¯å¾„éƒ½å¤±è´¥äº†
            return None
    
    def analyze_deepmath_structure(self, dataset):
        """åˆ†æDeepMathæ•°æ®é›†ç»“æ„
        
        è¿™ä¸ªæ–¹æ³•ä¼šï¼š
        1. æ˜¾ç¤ºæ•°æ®é›†çš„åŸºæœ¬ä¿¡æ¯ï¼ˆæ ·æœ¬æ•°ã€ç‰¹å¾åˆ—ï¼‰
        2. å±•ç¤ºå‰3ä¸ªæ ·æœ¬çš„è¯¦ç»†å†…å®¹
        3. å¸®åŠ©ç†è§£æ•°æ®é›†çš„ç»“æ„å’Œæ ¼å¼
        
        Args:
            dataset: è¦åˆ†æçš„æ•°æ®é›†å¯¹è±¡
        """
        if not dataset:
            return
        
        print(f"\nğŸ“ˆ DeepMathæ•°æ®é›†ç»“æ„åˆ†æ:")
        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {len(dataset)}")
        
        # åˆ†æç‰¹å¾åˆ—ï¼ˆå­—æ®µåï¼‰
        features = list(dataset.features.keys())
        print(f"ğŸ“‹ ç‰¹å¾åˆ—: {features}")
        
        # åˆ†æå‰å‡ ä¸ªæ ·æœ¬ï¼Œå±•ç¤ºæ•°æ®æ ¼å¼
        print(f"\nğŸ“ æ ·æœ¬ç¤ºä¾‹:")
        for i in range(min(3, len(dataset))):
            item = dataset[i]
            print(f"\n--- æ ·æœ¬ {i+1} ---")
            for key, value in item.items():
                if isinstance(value, str):
                    # å¦‚æœå­—ç¬¦ä¸²å¤ªé•¿ï¼Œåªæ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦
                    if len(value) > 200:
                        print(f"{key}: {value[:200]}...")
                    else:
                        print(f"{key}: {value}")
                else:
                    # éå­—ç¬¦ä¸²ç±»å‹ç›´æ¥æ˜¾ç¤º
                    print(f"{key}: {value}")
    
    def analyze_difficulty_distribution(self, dataset):
        """åˆ†æéš¾åº¦åˆ†å¸ƒ
        
        è¿™ä¸ªæ–¹æ³•ä¼šï¼š
        1. ç»Ÿè®¡æ¯ä¸ªéš¾åº¦ç­‰çº§çš„æ ·æœ¬æ•°é‡
        2. ç»Ÿè®¡æ¯ä¸ªæ•°å­¦ä¸»é¢˜çš„æ ·æœ¬æ•°é‡
        3. è®¡ç®—å„ç­‰çº§çš„ç™¾åˆ†æ¯”
        4. è¿”å›åˆ†å¸ƒç»Ÿè®¡ç»“æœ
        
        Args:
            dataset: è¦åˆ†æçš„æ•°æ®é›†å¯¹è±¡
            
        Returns:
            dict: åŒ…å«éš¾åº¦åˆ†å¸ƒå’Œä¸»é¢˜åˆ†å¸ƒçš„å­—å…¸
        """
        if not dataset:
            return
        
        print(f"\nğŸ“Š éš¾åº¦åˆ†å¸ƒåˆ†æ:")
        
        # åˆå§‹åŒ–ç»Ÿè®¡å­—å…¸
        difficulty_counts = {}  # å­˜å‚¨æ¯ä¸ªéš¾åº¦ç­‰çº§çš„æ ·æœ¬æ•°
        topic_counts = {}       # å­˜å‚¨æ¯ä¸ªä¸»é¢˜çš„æ ·æœ¬æ•°
        
        # éå†æ‰€æœ‰æ ·æœ¬ï¼Œç»Ÿè®¡åˆ†å¸ƒ
        for item in dataset:
            difficulty = item.get('difficulty', 'unknown')  # è·å–éš¾åº¦ç­‰çº§
            topic = item.get('topic', 'unknown')            # è·å–æ•°å­¦ä¸»é¢˜
            
            # ç´¯åŠ è®¡æ•°
            difficulty_counts[difficulty] = difficulty_counts.get(difficulty, 0) + 1
            topic_counts[topic] = topic_counts.get(topic, 0) + 1
        
        # æ˜¾ç¤ºéš¾åº¦ç­‰çº§åˆ†å¸ƒï¼ˆæŒ‰éš¾åº¦å€¼æ’åºï¼‰
        print(f"ğŸ“ˆ éš¾åº¦ç­‰çº§åˆ†å¸ƒ:")
        for difficulty in sorted(difficulty_counts.keys()):
            count = difficulty_counts[difficulty]
            percentage = (count / len(dataset)) * 100
            print(f"  {difficulty}: {count} ä¸ªæ ·æœ¬ ({percentage:.1f}%)")
        
        # æ˜¾ç¤ºæ•°å­¦ä¸»é¢˜åˆ†å¸ƒï¼ˆæŒ‰ä¸»é¢˜åæ’åºï¼‰
        print(f"\nğŸ“ˆ æ•°å­¦ä¸»é¢˜åˆ†å¸ƒ:")
        for topic in sorted(topic_counts.keys()):
            count = topic_counts[topic]
            percentage = (count / len(dataset)) * 100
            print(f"  {topic}: {count} ä¸ªæ ·æœ¬ ({percentage:.1f}%)")
        
        # è¿”å›ç»Ÿè®¡ç»“æœ
        return {
            'difficulty_distribution': difficulty_counts,
            'topic_distribution': topic_counts
        }
    
    def create_deepmath_evaluation_dataset(self, max_samples: int = 1000):
        """åˆ›å»ºDeepMathè¯„ä¼°æ•°æ®é›†ï¼ŒåŒ…å«æ‰€æœ‰éš¾åº¦ç­‰çº§
        
        è¿™ä¸ªæ–¹æ³•çš„æ ¸å¿ƒåŠŸèƒ½ï¼š
        1. åŠ è½½å®Œæ•´çš„DeepMathæ•°æ®é›†
        2. æŒ‰éš¾åº¦ç­‰çº§åˆ†ç»„æ‰€æœ‰æ ·æœ¬
        3. ä½¿ç”¨æ™ºèƒ½é‡‡æ ·ç­–ç•¥ï¼Œç¡®ä¿æ¯ä¸ªéš¾åº¦ç­‰çº§éƒ½æœ‰ä»£è¡¨æ€§æ ·æœ¬
        4. åˆ›å»ºåŒ…å«æ‰€æœ‰éš¾åº¦ç­‰çº§çš„è¯„ä¼°æ•°æ®é›†
        
        é‡‡æ ·ç­–ç•¥è¯´æ˜ï¼š
        - æ¯ä¸ªéš¾åº¦ç­‰çº§è‡³å°‘ä¿ç•™5ä¸ªæ ·æœ¬ï¼ˆå¦‚æœåŸå§‹æ•°é‡è¶³å¤Ÿï¼‰
        - å¯¹äºæ ·æœ¬è¾ƒå¤šçš„éš¾åº¦ç­‰çº§ï¼ŒæŒ‰æ¯”ä¾‹é‡‡æ ·ï¼Œä½†ä¸è¶…è¿‡åŸå§‹æ¯”ä¾‹çš„2å€
        - è¿™æ ·å¯ä»¥ç¡®ä¿ä½éš¾åº¦å’Œé«˜éš¾åº¦çš„æ ·æœ¬éƒ½ä¸ä¼šè¢«è¿‡åº¦é‡‡æ ·
        
        Args:
            max_samples: ç›®æ ‡æ€»æ ·æœ¬æ•°ï¼Œé»˜è®¤1000
            
        Returns:
            pd.DataFrame: åŒ…å«æ‰€æœ‰éš¾åº¦ç­‰çº§çš„è¯„ä¼°æ•°æ®é›†
        """
        print(f"\nğŸ“¥ åˆ›å»ºDeepMathè¯„ä¼°æ•°æ®é›†ï¼ˆåŒ…å«æ‰€æœ‰éš¾åº¦ç­‰çº§ï¼‰...")
        
        try:
            # åŠ è½½å®Œæ•´æ•°æ®é›†
            dataset = self.try_load_deepmath()
            if not dataset:
                print("âŒ æ— æ³•åŠ è½½DeepMathæ•°æ®é›†")
                return
            
            # åˆ†ææ•°æ®é›†ç»“æ„
            self.analyze_deepmath_structure(dataset)
            
            # åˆ†æéš¾åº¦åˆ†å¸ƒ
            distribution = self.analyze_difficulty_distribution(dataset)
            
            # åˆ›å»ºè¯„ä¼°æ•°æ®é›†åˆ—è¡¨
            evaluation_data = []
            
            # ç¬¬ä¸€æ­¥ï¼šæŒ‰éš¾åº¦ç­‰çº§åˆ†ç»„æ‰€æœ‰æ ·æœ¬
            difficulty_groups = {}
            for item in dataset:
                difficulty = item.get('difficulty', 'unknown')
                if difficulty not in difficulty_groups:
                    difficulty_groups[difficulty] = []
                difficulty_groups[difficulty].append(item)
            
            # ç¬¬äºŒæ­¥ï¼šè®¡ç®—æ¯ä¸ªéš¾åº¦ç­‰çº§çš„é‡‡æ ·æ•°é‡
            # ä½¿ç”¨æ™ºèƒ½é‡‡æ ·ç­–ç•¥ï¼Œç¡®ä¿æ¯ä¸ªéš¾åº¦ç­‰çº§éƒ½æœ‰ä»£è¡¨æ€§æ ·æœ¬
            total_original_samples = len(dataset)
            difficulty_sampling = {}
            
            for difficulty, items in difficulty_groups.items():
                original_count = len(items)
                original_ratio = original_count / total_original_samples
                
                # é‡‡æ ·ç­–ç•¥ï¼š
                # 1. ç¡®ä¿æ¯ä¸ªéš¾åº¦ç­‰çº§è‡³å°‘æœ‰5ä¸ªæ ·æœ¬ï¼ˆå¦‚æœåŸå§‹æ•°é‡è¶³å¤Ÿï¼‰
                # 2. å¯¹äºæ ·æœ¬è¾ƒå¤šçš„éš¾åº¦ç­‰çº§ï¼ŒæŒ‰æ¯”ä¾‹é‡‡æ ·ï¼Œä½†ä¸è¶…è¿‡åŸå§‹æ¯”ä¾‹çš„2å€
                min_samples = min(5, original_count)
                max_samples_for_difficulty = min(max_samples * original_ratio * 2, original_count)
                target_samples = max(min_samples, int(max_samples_for_difficulty))
                
                difficulty_sampling[difficulty] = target_samples
            
            # æ˜¾ç¤ºé‡‡æ ·ç­–ç•¥
            print(f"ğŸ“Š é‡‡æ ·ç­–ç•¥:")
            for difficulty, target in sorted(difficulty_sampling.items(), key=lambda x: float(x[0])):
                original_count = len(difficulty_groups[difficulty])
                print(f"  éš¾åº¦ {difficulty}: {original_count} -> {target} ä¸ªæ ·æœ¬")
            
            # ç¬¬ä¸‰æ­¥ï¼šä»æ¯ä¸ªéš¾åº¦ç­‰çº§é‡‡æ ·
            for difficulty, items in difficulty_groups.items():
                target_samples = difficulty_sampling[difficulty]
                
                # éšæœºé‡‡æ ·ï¼Œç¡®ä¿æ ·æœ¬çš„éšæœºæ€§
                import random
                sampled_items = random.sample(items, min(target_samples, len(items)))
                
                # å¤„ç†æ¯ä¸ªé‡‡æ ·çš„æ ·æœ¬
                for i, item in enumerate(sampled_items):
                    processed_item = self.process_deepmath_item(item, difficulty, i)
                    if processed_item:
                        evaluation_data.append(processed_item)
            
            # ç¬¬å››æ­¥ï¼šåˆ›å»ºDataFrameå¹¶ä¿å­˜
            df = pd.DataFrame(evaluation_data)
            
            # ä¿å­˜åˆ°CSVæ–‡ä»¶
            output_file = Path("data/processed") / "deepmath_evaluation_dataset.csv"
            output_file.parent.mkdir(parents=True, exist_ok=True)
            df.to_csv(output_file, index=False)
            
            print(f"âœ… DeepMathè¯„ä¼°æ•°æ®é›†å·²ä¿å­˜: {output_file}")
            print(f"ğŸ“Š æ ·æœ¬æ•°: {len(df)}")
            
            # æ˜¾ç¤ºæœ€ç»ˆæ•°æ®é›†çš„éš¾åº¦åˆ†å¸ƒ
            difficulty_stats = df['difficulty'].value_counts()
            print(f"ğŸ“ˆ æœ€ç»ˆéš¾åº¦åˆ†å¸ƒ:")
            for difficulty, count in difficulty_stats.items():
                print(f"  {difficulty}: {count} ä¸ªæ ·æœ¬")
            
            # æ˜¾ç¤ºæœ€ç»ˆæ•°æ®é›†çš„ä¸»é¢˜åˆ†å¸ƒ
            topic_stats = df['topic'].value_counts()
            print(f"ğŸ“ˆ æœ€ç»ˆä¸»é¢˜åˆ†å¸ƒ:")
            for topic, count in topic_stats.items():
                print(f"  {topic}: {count} ä¸ªæ ·æœ¬")
            
            return df
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºDeepMathè¯„ä¼°æ•°æ®é›†å¤±è´¥: {e}")
            print(f"âŒ é”™è¯¯: {e}")
            return None
    
    def process_deepmath_item(self, item: Dict, difficulty: str, index: int) -> Optional[Dict]:
        """å¤„ç†DeepMathæ•°æ®é¡¹
        
        å°†åŸå§‹DeepMathæ•°æ®é¡¹è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œç”¨äºè¯„ä¼°
        
        Args:
            item: åŸå§‹æ•°æ®é¡¹
            difficulty: éš¾åº¦ç­‰çº§
            index: æ ·æœ¬ç´¢å¼•
            
        Returns:
            dict: å¤„ç†åçš„æ ‡å‡†æ ¼å¼æ•°æ®é¡¹ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            return {
                'id': f"deepmath_{difficulty}_{index}",  # å”¯ä¸€æ ‡è¯†ç¬¦
                'problem': item.get('question', ''),     # æ•°å­¦é—®é¢˜
                'solution': self.extract_solution(item), # è§£ç­”æ­¥éª¤
                'answer': item.get('final_answer', ''),  # æœ€ç»ˆç­”æ¡ˆ
                'difficulty': difficulty,                # éš¾åº¦ç­‰çº§
                'topic': item.get('topic', 'unknown'),   # æ•°å­¦ä¸»é¢˜
                'difficulty_score': item.get('difficulty', 0),  # æ•°å€¼éš¾åº¦åˆ†æ•°
                'source_dataset': 'deepmath'             # æ•°æ®æ¥æº
            }
        except Exception as e:
            self.logger.error(f"å¤„ç†DeepMathé¡¹ç›®å¤±è´¥: {e}")
            return None
    
    def extract_solution(self, item: Dict) -> str:
        """æå–è§£ç­”æ­¥éª¤
        
        ä»DeepMathæ•°æ®é¡¹ä¸­æå–è§£ç­”ä¿¡æ¯
        
        Args:
            item: æ•°æ®é¡¹
            
        Returns:
            str: è§£ç­”æ­¥éª¤æˆ–åŸºæœ¬ä¿¡æ¯
        """
        # å°è¯•æå–R1è§£ç­”ï¼ˆç¬¬ä¸€ä¸ªè§£ç­”è€…çš„è§£ç­”ï¼‰
        r1_solutions = item.get('r1_solutions', [])
        if r1_solutions and len(r1_solutions) > 0:
            return r1_solutions[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªè§£ç­”
        
        # å¦‚æœæ²¡æœ‰R1è§£ç­”ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
        return f"Topic: {item.get('topic', 'unknown')}, Difficulty: {item.get('difficulty', 'unknown')}"
    
    def save_deepmath_info(self, dataset):
        """ä¿å­˜DeepMathæ•°æ®é›†ä¿¡æ¯
        
        å°†æ•°æ®é›†çš„åŸºæœ¬ä¿¡æ¯ã€åˆ†å¸ƒç»Ÿè®¡å’Œæ ·æœ¬ç¤ºä¾‹ä¿å­˜åˆ°JSONæ–‡ä»¶
        
        Args:
            dataset: è¦ä¿å­˜ä¿¡æ¯çš„æ•°æ®é›†å¯¹è±¡
        """
        if not dataset:
            return
        
        # åˆ†æéš¾åº¦åˆ†å¸ƒå’Œä¸»é¢˜åˆ†å¸ƒ
        distribution = self.analyze_difficulty_distribution(dataset)
        
        # æ„å»ºæ•°æ®é›†ä¿¡æ¯å­—å…¸
        info = {
            'dataset_name': self.deepmath_info['name'],           # æ•°æ®é›†åç§°
            'description': self.deepmath_info['description'],     # æ•°æ®é›†æè¿°
            'paper': self.deepmath_info['paper'],                 # ç›¸å…³è®ºæ–‡
            'difficulty_levels': self.deepmath_info['difficulty_levels'],  # å®˜æ–¹éš¾åº¦ç­‰çº§
            'topics': self.deepmath_info['topics'],               # ä¸»è¦æ•°å­¦ä¸»é¢˜
            'total_samples': len(dataset),                        # æ€»æ ·æœ¬æ•°
            'features': list(dataset.features.keys()) if hasattr(dataset, 'features') else [],  # ç‰¹å¾åˆ—
            'difficulty_distribution': distribution['difficulty_distribution'],  # éš¾åº¦åˆ†å¸ƒ
            'topic_distribution': distribution['topic_distribution'],            # ä¸»é¢˜åˆ†å¸ƒ
            'sample_data': []                                     # æ ·æœ¬ç¤ºä¾‹
        }
        
        # ä¿å­˜å‰3ä¸ªæ ·æœ¬ä½œä¸ºç¤ºä¾‹
        for i in range(min(3, len(dataset))):
            sample = dataset[i]
            info['sample_data'].append(sample)
        
        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        output_file = Path("data") / "deepmath_dataset_info.json"
        output_file.parent.mkdir(exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ DeepMathæ•°æ®é›†ä¿¡æ¯å·²ä¿å­˜: {output_file}")

def main():
    """ä¸»å‡½æ•°ï¼šå¤„ç†å‘½ä»¤è¡Œå‚æ•°å¹¶æ‰§è¡Œç›¸åº”æ“ä½œ"""
    parser = argparse.ArgumentParser(description="æ¢ç´¢DeepMathæ•°æ®é›†")
    parser.add_argument("--explore", action="store_true", 
                       help="æ¢ç´¢DeepMathæ•°æ®é›†ç»“æ„å’ŒåŸºæœ¬ä¿¡æ¯")
    parser.add_argument("--analyze", action="store_true", 
                       help="åˆ†æéš¾åº¦åˆ†å¸ƒå’Œä¸»é¢˜åˆ†å¸ƒ")
    parser.add_argument("--create-dataset", action="store_true", 
                       help="åˆ›å»ºåŒ…å«æ‰€æœ‰éš¾åº¦ç­‰çº§çš„è¯„ä¼°æ•°æ®é›†")
    parser.add_argument("--max-samples", type=int, default=500, 
                       help="è¯„ä¼°æ•°æ®é›†çš„æœ€å¤§æ ·æœ¬æ•°ï¼ˆé»˜è®¤500ï¼‰")
    parser.add_argument("--all", action="store_true", 
                       help="æ‰§è¡Œæ‰€æœ‰æ“ä½œï¼šæ¢ç´¢ã€åˆ†æã€åˆ›å»ºæ•°æ®é›†")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ¢ç´¢å™¨å®ä¾‹
    explorer = DeepMathDatasetExplorer()
    
    # æ ¹æ®å‚æ•°æ‰§è¡Œç›¸åº”æ“ä½œ
    if args.explore or args.all:
        # æ¢ç´¢æ•°æ®é›†ç»“æ„
        dataset = explorer.try_load_deepmath()
        if dataset:
            explorer.analyze_deepmath_structure(dataset)
            explorer.save_deepmath_info(dataset)
    
    if args.analyze or args.all:
        # åˆ†æéš¾åº¦åˆ†å¸ƒ
        dataset = explorer.try_load_deepmath()
        if dataset:
            explorer.analyze_difficulty_distribution(dataset)
    
    if args.create_dataset or args.all:
        # åˆ›å»ºè¯„ä¼°æ•°æ®é›†
        explorer.create_deepmath_evaluation_dataset(args.max_samples)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•å‚æ•°ï¼Œæ‰§è¡Œé»˜è®¤æ“ä½œ
    if not any([args.explore, args.analyze, args.create_dataset, args.all]):
        print("ğŸ” æ‰§è¡Œé»˜è®¤æ“ä½œï¼šæ¢ç´¢DeepMathæ•°æ®é›†")
        dataset = explorer.try_load_deepmath()
        if dataset:
            explorer.analyze_deepmath_structure(dataset)
            explorer.analyze_difficulty_distribution(dataset)
            explorer.save_deepmath_info(dataset)

if __name__ == "__main__":
    main() 