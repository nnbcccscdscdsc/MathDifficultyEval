#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DeepMath-103Kæ•°æ®é›†Qwenæ¨¡å‹ç»“æœå¯è§†åŒ–è„šæœ¬
ç”Ÿæˆä¸DeepSeek R1ç³»åˆ—ç›¸åŒæ ·å¼çš„å¯¹æ¯”å›¾
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import pandas as pd
from collections import defaultdict
import logging

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class DeepMath103KQwenPlotter:
    """DeepMath-103Kæ•°æ®é›†Qwenæ¨¡å‹ç»“æœå¯è§†åŒ–ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.results_dir = Path("data/results")
        
        # Qwenæ¨¡å‹é…ç½®
        self.models = {
            "Qwen_Qwen2.5_0.5B_Instruct": {
                "short_name": "0.5B",
                "color": "#FF6B6B",  # çº¢è‰²
                "marker": "o",
                "linewidth": 2,
                "markersize": 6
            },
            "Qwen_Qwen2.5_1.5B_Instruct": {
                "short_name": "1.5B", 
                "color": "#4ECDC4",  # é’è‰²
                "marker": "s",
                "linewidth": 2,
                "markersize": 6
            },
            "Qwen_Qwen2.5_3B_Instruct": {
                "short_name": "3B",
                "color": "#45B7D1",  # è“è‰²
                "marker": "^",
                "linewidth": 2,
                "markersize": 6
            },
            "Qwen_Qwen2.5_7B_Instruct": {
                "short_name": "7B",
                "color": "#96CEB4",  # ç»¿è‰²
                "marker": "D",
                "linewidth": 2,
                "markersize": 6
            },
            "Qwen_Qwen2.5_14B_Instruct": {
                "short_name": "14B",
                "color": "#FFEAA7",  # é»„è‰²
                "marker": "*",
                "linewidth": 2,
                "markersize": 8
            },
            "Qwen_Qwen2.5_32B_Instruct": {
                "short_name": "32B",
                "color": "#DDA0DD",  # ç´«è‰²
                "marker": "v",
                "linewidth": 2,
                "markersize": 6
            },
            "Qwen_Qwen2.5_72B_Instruct": {
                "short_name": "72B",
                "color": "#FF8C42",  # æ©™è‰²
                "marker": "p",
                "linewidth": 2,
                "markersize": 6
            }
        }
        
        # éš¾åº¦ç­‰çº§é¢œè‰²é…ç½®ï¼ˆç¡®ä¿3å’Œ8æœ‰è¶³å¤ŸåŒºåˆ†åº¦ï¼‰
        self.level_colors = {
            3: "#FF6B6B",  # çº¢è‰²
            4: "#4ECDC4",  # é’è‰²
            5: "#45B7D1",  # è“è‰²
            6: "#96CEB4",  # ç»¿è‰²
            7: "#FFEAA7",  # é»„è‰²
            8: "#8B4513"   # æ·±æ£•è‰²ï¼ˆä¸3çš„çº¢è‰²æœ‰å¾ˆå¥½åŒºåˆ†ï¼‰
        }
        
        self.level_markers = {
            3: "o",
            4: "s", 
            5: "^",
            6: "D",
            7: "*",
            8: "v"
        }
        
        self.logger = logging.getLogger(__name__)
        
    def load_model_results(self):
        """åŠ è½½æ‰€æœ‰Qwenæ¨¡å‹çš„ç»“æœ"""
        all_results = {}
        
        for model_name in self.models.keys():
            # æŸ¥æ‰¾å¯¹åº”çš„ç»“æœæ–‡ä»¶
            pattern = f"final_evaluation_{model_name}_*.json"
            result_files = list(self.results_dir.glob(pattern))
            
            if result_files:
                # é€‰æ‹©æœ€æ–°çš„ç»“æœæ–‡ä»¶
                latest_file = max(result_files, key=lambda x: x.stat().st_mtime)
                self.logger.info(f"ğŸ“Š åŠ è½½æ¨¡å‹ {model_name} ç»“æœ: {latest_file.name}")
                
                try:
                    with open(latest_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        all_results[model_name] = data
                except Exception as e:
                    self.logger.error(f"âŒ åŠ è½½ {latest_file} å¤±è´¥: {e}")
            else:
                self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ¨¡å‹ {model_name} çš„ç»“æœæ–‡ä»¶")
        
        return all_results
    
    def analyze_results_by_difficulty(self, results):
        """æŒ‰éš¾åº¦åˆ†æç»“æœ"""
        difficulty_data = defaultdict(lambda: defaultdict(list))
        
        for model_name, model_data in results.items():
            if 'results' not in model_data:
                continue
                
            for result in model_data['results']:
                # æå–éš¾åº¦å’Œåˆ†æ•°
                difficulty = result.get('difficulty')
                score = result.get('evaluation', {}).get('overall_score', 0)
                
                # åªå¤„ç†æ•´æ•°éš¾åº¦3-8
                if difficulty is not None and isinstance(difficulty, (int, float)):
                    difficulty_int = int(difficulty)
                    if 3 <= difficulty_int <= 8:
                        difficulty_data[model_name][difficulty_int].append(score)
        
        return difficulty_data
    
    def create_deepmath_qwen_plot(self, all_difficulty_data):
        """åˆ›å»ºDeepMath-103K Qwenç»“æœå›¾"""
        # è®¾ç½®å›¾å½¢æ ·å¼
        plt.style.use('default')
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        
        # æ”¶é›†æ‰€æœ‰éš¾åº¦ç­‰çº§
        all_levels = set()
        for model_name, difficulty_data in all_difficulty_data.items():
            if difficulty_data:
                all_levels.update(difficulty_data.keys())
        
        all_levels = sorted(list(all_levels))
        
        # æ”¶é›†æ‰€æœ‰æ¨¡å‹å‚æ•°
        model_params = []
        for model_name, difficulty_data in all_difficulty_data.items():
            if difficulty_data:
                short_name = self.models[model_name]["short_name"]
                model_params.append(short_name)
        
        # å›¾1: Model Performance by Difficulty Level (å·¦å›¾)
        ax1.set_title('(a) Model Performance by Difficulty Level', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Model Parameters', fontsize=12)
        ax1.set_ylabel('Average Score', fontsize=12)
        ax1.set_ylim(5.0, 10.0)
        ax1.grid(True, alpha=0.3)
        ax1.set_facecolor('#f8f9fa')
        
        # ä¸ºæ¯ä¸ªéš¾åº¦ç­‰çº§ç»˜åˆ¶ä¸€æ¡çº¿
        for level in all_levels:
            scores = []
            for model_name, difficulty_data in all_difficulty_data.items():
                if difficulty_data and level in difficulty_data:
                    avg_score = np.mean(difficulty_data[level])
                    scores.append(avg_score)
                else:
                    scores.append(np.nan)
            
            # è¿‡æ»¤æ‰NaNå€¼
            valid_scores = [(i, s) for i, s in enumerate(scores) if not np.isnan(s)]
            if valid_scores:
                x_positions = [valid_scores[i][0] for i in range(len(valid_scores))]
                y_scores = [valid_scores[i][1] for i in range(len(valid_scores))]
                
                ax1.plot(x_positions, y_scores, 
                        color=self.level_colors[level],
                        marker=self.level_markers[level],
                        linewidth=2,
                        markersize=6,
                        label=f'Level {level}')
        
        # è®¾ç½®Xè½´æ ‡ç­¾
        ax1.set_xticks(range(len(model_params)))
        ax1.set_xticklabels(model_params, rotation=45)
        ax1.legend(loc='lower left', bbox_to_anchor=(0, 0), fontsize=10)
        
        # å›¾2: Average Qwen Series Model Performance Analysis by Difficulty (å³å›¾)
        ax2.set_title('(b) Average Qwen Series Model Performance Analysis by Difficulty', 
                     fontsize=14, fontweight='bold')
        ax2.set_xlabel('Problem Difficulty', fontsize=12)
        ax2.set_ylabel('Average Score', fontsize=12)
        ax2.set_xlim(2.5, 8.5)
        ax2.set_ylim(5.0, 10.0)
        ax2.set_xticks(all_levels)
        ax2.grid(True, alpha=0.3)
        ax2.set_facecolor('#f8f9fa')
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹ç»˜åˆ¶ä¸€æ¡çº¿
        for model_name, difficulty_data in all_difficulty_data.items():
            if difficulty_data:
                levels = []
                avg_scores = []
                
                for level in all_levels:
                    if level in difficulty_data:
                        scores = difficulty_data[level]
                        levels.append(level)
                        avg_scores.append(np.mean(scores))
                
                if levels:
                    config = self.models[model_name]
                    ax2.plot(levels, avg_scores,
                            color=config["color"],
                            marker=config["marker"],
                            linewidth=config["linewidth"],
                            markersize=config["markersize"],
                            label=config["short_name"])
        
        ax2.legend(loc='upper right', fontsize=10)
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡åˆ°plot_dataç›®å½•
        plot_data_dir = Path("plot_data")
        plot_data_dir.mkdir(exist_ok=True)
        output_path = plot_data_dir / "deepmath_103k_qwen_comparison.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        self.logger.info(f"ğŸ’¾ å›¾ç‰‡å·²ä¿å­˜: {output_path}")
        
        plt.show()
        
        return len(all_difficulty_data)
    
    def generate_summary_report(self, all_difficulty_data):
        """ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š"""
        report_lines = []
        report_lines.append("="*60)
        report_lines.append("ğŸ“Š DeepMath-103K Qwenæ¨¡å‹è¯„ä¼°ç»“æœæ‘˜è¦")
        report_lines.append("="*60)
        
        total_samples = 0
        for model_name, difficulty_data in all_difficulty_data.items():
            model_samples = sum(len(scores) for scores in difficulty_data.values())
            total_samples += model_samples
            line = f"ğŸ¤– {self.models[model_name]['short_name']}: {model_samples} ä¸ªæ ·æœ¬"
            report_lines.append(line)
            print(line)
        
        summary_lines = [
            f"\nğŸ“ˆ æ€»æ ·æœ¬æ•°: {total_samples}",
            f"ğŸ¯ éš¾åº¦èŒƒå›´: 3-8 (æ•´æ•°)",
            f"ğŸ“Š è¯„åˆ†èŒƒå›´: 5.0-10.0",
            "="*60
        ]
        
        for line in summary_lines:
            report_lines.append(line)
            print(line)
        
        # ä¿å­˜æŠ¥å‘Šåˆ°plot_dataç›®å½•
        plot_data_dir = Path("plot_data")
        plot_data_dir.mkdir(exist_ok=True)
        report_path = plot_data_dir / "deepmath_103k_qwen_summary_report.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        
        self.logger.info(f"ğŸ’¾ æ‘˜è¦æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        return report_lines
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        self.logger.info("ğŸš€ å¼€å§‹DeepMath-103K Qwenç»“æœåˆ†æ...")
        
        # åŠ è½½ç»“æœ
        results = self.load_model_results()
        if not results:
            self.logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•Qwenæ¨¡å‹ç»“æœ")
            return
        
        # åˆ†ææ•°æ®
        all_difficulty_data = self.analyze_results_by_difficulty(results)
        
        # ç”Ÿæˆå›¾è¡¨
        model_count = self.create_deepmath_qwen_plot(all_difficulty_data)
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_summary_report(all_difficulty_data)
        
        self.logger.info(f"âœ… åˆ†æå®Œæˆï¼Œå…±å¤„ç† {model_count} ä¸ªæ¨¡å‹")

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # åˆ›å»ºç»˜å›¾å™¨å¹¶è¿è¡Œåˆ†æ
    plotter = DeepMath103KQwenPlotter()
    plotter.run_analysis()

if __name__ == "__main__":
    main() 