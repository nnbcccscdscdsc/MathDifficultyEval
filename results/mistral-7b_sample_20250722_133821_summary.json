{
  "model_name": "mistral-7b",
  "dataset_name": "sample",
  "total_samples": 5,
  "evaluation_time": "2025-07-22T13:38:21.035624",
  "overall_metrics": {
    "accuracy": 0.0,
    "exact_match": 0.0,
    "rouge_score": 0.0,
    "bleu_score": 0.0
  },
  "difficulty_metrics": {
    "elementary": {
      "sample_count": 1,
      "avg_generation_time": 0.7526042461395264,
      "avg_accuracy": 0.0,
      "avg_exact_match": 0.0,
      "avg_rouge_score": 0.0,
      "avg_bleu_score": 0.0
    },
    "middle": {
      "sample_count": 1,
      "avg_generation_time": 0.2807924747467041,
      "avg_accuracy": 0.0,
      "avg_exact_match": 0.0,
      "avg_rouge_score": 0.0,
      "avg_bleu_score": 0.0
    },
    "college": {
      "sample_count": 3,
      "avg_generation_time": 0.05720678965250651,
      "avg_accuracy": 0.0,
      "avg_exact_match": 0.0,
      "avg_rouge_score": 0.0,
      "avg_bleu_score": 0.0
    }
  }
}